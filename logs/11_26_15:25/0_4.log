Training with n_layers: 0 and n_single_qubit_params: 4
Train Loss:
[1.0892448172507512, 0.9986832028233821, 1.2437961772998694, 1.2552540587292627, 1.3281463729896652, 1.0774358988842447, 0.8626125984807856, 1.1073839085660557, 1.514071021813508, 0.8829176081979044, 0.7831899724773068, 0.74339690018833, 0.7393140478072535, 0.8034877301036284, 0.746182908406298, 0.7837097260715735, 0.714897964215922, 0.7493059865738273, 0.7193753423548401, 0.6974974040296179, 0.6713521303402403, 0.8320114606946323, 0.8112554864135113, 1.0578799074315248, 1.0592029146264335, 1.0227043128190083, 0.9789465836644134, 0.9452083413739747, 1.1049113085964288, 1.2259904235936918, 1.092488897136721, 0.8801337442186452, 1.1464603280776908, 0.9233087948392474, 0.7878164736461821, 0.765194299915293, 0.7929546964114957, 0.721030674541823, 0.7241431387632797, 0.7432544056042479, 1.1774701770077756, 0.7977697543484576, 0.8345261658139481, 0.7976575578053746, 0.7805410664438371, 0.7431603952758563, 0.7092535227994283, 0.7466195171840474, 0.7134759833007553, 0.7573962064224553, 0.7430975513562871, 0.6980184798768384, 0.7236175948827551, 0.9889237834662875, 0.730933078193976, 0.7444556178364609, 0.733299532418796, 0.7305154028376217, 0.7030740123818087, 0.7245993893880669, 0.6957366800377116, 0.7277429338379245, 0.7089500600844965, 0.7068114491307249, 0.7219242443382102, 0.7082578838837101, 0.7006555104891189, 0.6843540364116596, 0.701830983749986, 0.6871123632124477, 0.7079211093552134, 0.7240801524922935, 0.6756091963580643, 0.711037044480014, 0.6996267093941955, 0.7034504313019324, 0.710105520692858, 0.6591795413935269, 0.6696038906466304, 0.6809746179524078, 0.6767100153105339, 0.8354841212589882, 0.6635562856342061, 0.6800947785501217, 0.6658979930635197, 0.662683659312546, 0.6581723366580698, 0.653897943507135, 0.645839409325145, 0.6787694858919371, 0.649244718220638, 0.6740464733832128, 0.6602968091273566, 0.6980220143843502, 0.6576579125316406, 0.6670543685593117, 0.6706288630584606, 0.6672675094231949, 0.6684785250563992, 0.6815886903073665, 0.6933531636072422, 0.6492567109395692, 0.6529814583424738, 0.6483520188820916, 0.6775862807226113, 0.6330511985662172, 0.6422252552158394, 0.6354207669390792, 0.6879172271390707, 0.6669353136005182, 0.6632792596123596, 0.6602763278251871, 0.6393029119727308, 0.6518596918947064, 0.6564175651152606, 0.6679440868581511, 0.6753707094733592, 0.6442339527117446, 0.6293713510700073, 0.6778575829619666]
Validation Loss:
[0.6407121598192037, 0.7085403300448072, 0.8712137353787176, 1.1287321429333097, 1.5860432319336983, 0.9618205462044115, 0.9522409085930601, 1.4746278773395882, 1.1659879762664542, 0.9624038853483731, 0.8843995001163666, 1.0142207011994453, 1.0416627086331, 1.0438086420044919, 1.148755687306861, 0.9461006973784086, 0.9398719858435929, 0.9972154923497949, 0.9424133277397446, 0.9024258823476455, 0.898157117444061, 1.0313952389786154, 1.0678533371930183, 1.0123476894288854, 1.097470117208124, 1.0115584018530464, 0.9334656284832824, 0.9693426250241542, 0.8860799934550012, 0.8270221771496667, 0.883560816451182, 0.8033370218756493, 0.8886531734989186, 0.8930235509650426, 0.8611964266102059, 0.8499468935680256, 0.8587745601206964, 0.8737269554979702, 0.8552076656554112, 0.9277864627863598, 0.6749533146954796, 0.7006105482281665, 0.6932332262958835, 0.6821978295411255, 0.6971057525748355, 0.7026288768239954, 0.6910408978106377, 0.7069599762224245, 0.720585157669952, 0.7092833943128216, 0.7463091893604329, 0.7346196734745987, 0.7080650805163108, 0.7866126548984238, 0.7698318361092653, 0.7797163678756445, 0.7814143713273578, 0.7693262623789313, 0.7525154926787665, 0.7611351545418229, 0.7630082484791193, 0.7588617064386173, 0.8412092048371971, 0.8350700821955795, 0.7627118980372277, 0.787491645864539, 0.7944376270303025, 0.7955018701298991, 0.7636774228603077, 0.7687772157437373, 0.7861752006826431, 0.7813173142205694, 0.7619828026344031, 0.7491720110579865, 0.7616870995159909, 0.778992604110931, 0.804492833186576, 0.7873965690260094, 0.7774249463532227, 0.7389364134455084, 0.7475647696336645, 0.7974503240332006, 0.8157626448113047, 0.8148706806888731, 0.8079810541653, 0.8446159449855327, 0.8430848734140564, 0.8097927850648142, 0.8045343592280438, 0.8198416638534041, 0.8559460124258618, 0.8049424471794341, 0.8075064524033208, 0.8640372058379504, 0.8565007202279032, 0.8652911552007511, 0.8347779740630727, 0.845069453037616, 0.8514452444682126, 0.8236579060793718, 0.8465792170141356, 0.8289459581216576, 0.838220755315504, 0.8489869975266295, 0.8336878814099508, 0.8291743956545938, 0.8320221807010133, 0.8597635537822248, 0.8684444028786475, 0.8603775881520177, 0.9032416345264755, 0.8742859409970525, 0.9423521159778351, 0.8868080658509782, 0.8948247032600207, 0.8635994582110021, 0.877273622903551, 0.8578607402796457, 0.8629165238139657, 0.8654947922826773]
Train Accuracy:
[0.39285714285714285, 0.42857142857142855, 0.4, 0.4, 0.4857142857142857, 0.6, 0.45, 0.6, 0.6, 0.4142857142857143, 0.5285714285714286, 0.5142857142857142, 0.6428571428571429, 0.6214285714285714, 0.5571428571428572, 0.5571428571428572, 0.5642857142857143, 0.6714285714285714, 0.5714285714285714, 0.5857142857142857, 0.5714285714285714, 0.5357142857142857, 0.5357142857142857, 0.4142857142857143, 0.44285714285714284, 0.5, 0.5, 0.5, 0.5, 0.45, 0.45714285714285713, 0.4857142857142857, 0.4714285714285714, 0.4642857142857143, 0.5857142857142857, 0.5, 0.5428571428571428, 0.5571428571428572, 0.55, 0.5714285714285714, 0.5571428571428572, 0.45, 0.45714285714285713, 0.4, 0.5571428571428572, 0.5285714285714286, 0.5142857142857142, 0.4785714285714286, 0.5428571428571428, 0.42857142857142855, 0.6142857142857143, 0.6285714285714286, 0.5714285714285714, 0.55, 0.5, 0.5642857142857143, 0.5142857142857142, 0.4857142857142857, 0.5428571428571428, 0.5428571428571428, 0.6, 0.42142857142857143, 0.6, 0.5, 0.6285714285714286, 0.5714285714285714, 0.5142857142857142, 0.5714285714285714, 0.6, 0.5571428571428572, 0.6285714285714286, 0.5285714285714286, 0.5714285714285714, 0.6142857142857143, 0.4714285714285714, 0.5, 0.5714285714285714, 0.65, 0.6071428571428571, 0.5142857142857142, 0.6, 0.6214285714285714, 0.5857142857142857, 0.5571428571428572, 0.6, 0.6285714285714286, 0.6142857142857143, 0.6714285714285714, 0.6142857142857143, 0.5142857142857142, 0.6571428571428571, 0.6428571428571429, 0.7, 0.6428571428571429, 0.6, 0.6, 0.6142857142857143, 0.55, 0.6642857142857143, 0.4857142857142857, 0.5714285714285714, 0.5857142857142857, 0.5285714285714286, 0.6571428571428571, 0.5714285714285714, 0.6714285714285714, 0.6142857142857143, 0.6214285714285714, 0.6142857142857143, 0.6, 0.5857142857142857, 0.6428571428571429, 0.6214285714285714, 0.5857142857142857, 0.5642857142857143, 0.6714285714285714, 0.5714285714285714, 0.5571428571428572, 0.5714285714285714, 0.6142857142857143]
Validation Accuracy:
[0.5666666666666667, 0.6, 0.6333333333333333, 0.5, 0.36666666666666664, 0.36666666666666664, 0.4, 0.43333333333333335, 0.4666666666666667, 0.4, 0.4, 0.43333333333333335, 0.4666666666666667, 0.36666666666666664, 0.36666666666666664, 0.36666666666666664, 0.4, 0.4, 0.5, 0.48333333333333334, 0.5, 0.5, 0.5, 0.5333333333333333, 0.5333333333333333, 0.5333333333333333, 0.5, 0.5, 0.43333333333333335, 0.5333333333333333, 0.5, 0.5, 0.5333333333333333, 0.4666666666666667, 0.43333333333333335, 0.4, 0.48333333333333334, 0.4, 0.43333333333333335, 0.43333333333333335, 0.5666666666666667, 0.5333333333333333, 0.5333333333333333, 0.6, 0.5333333333333333, 0.5333333333333333, 0.4666666666666667, 0.4666666666666667, 0.5, 0.4666666666666667, 0.5, 0.5, 0.43333333333333335, 0.5333333333333333, 0.4666666666666667, 0.4666666666666667, 0.4666666666666667, 0.43333333333333335, 0.43333333333333335, 0.43333333333333335, 0.36666666666666664, 0.4, 0.43333333333333335, 0.43333333333333335, 0.43333333333333335, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4, 0.4166666666666667, 0.4, 0.4, 0.43333333333333335, 0.4166666666666667, 0.4, 0.43333333333333335, 0.4, 0.4666666666666667, 0.4666666666666667, 0.4, 0.43333333333333335, 0.36666666666666664, 0.43333333333333335, 0.43333333333333335, 0.45, 0.43333333333333335, 0.4, 0.4166666666666667, 0.43333333333333335, 0.4, 0.4, 0.4, 0.4, 0.36666666666666664, 0.4, 0.4, 0.4666666666666667, 0.36666666666666664, 0.4, 0.43333333333333335, 0.36666666666666664, 0.4, 0.4, 0.43333333333333335, 0.4, 0.4, 0.4, 0.5333333333333333, 0.43333333333333335, 0.55, 0.5166666666666667, 0.5333333333333333, 0.5666666666666667, 0.4, 0.5, 0.5]
