Training with n_layers: 4 and n_single_qubit_params: 4
Train Loss:
[1.0540160677357269, 0.8999655587520387, 0.849050314789797, 0.935879202973407, 1.2454330603325756, 0.9342497057541836, 1.0571377562942945, 1.0765358150283384, 1.0419467272403005, 0.8366827342696681, 1.086225864612339, 0.8095219361454685, 1.0967135043458938, 0.8123530647105006, 0.7524809715854945, 0.7644558091775392, 0.6638211942370633, 0.9188612488925783, 0.7432612405537239, 0.7326669141442286, 0.7048615502176784, 0.7784203041965032, 0.7466920590512715, 0.7046159662068081, 0.6710303286396784, 0.716380787096176, 0.8245963058876583, 0.6142749146067918, 0.6179789660190599, 0.5452310674288646, 0.58919532297356, 0.5328351949043709, 0.5364662308934562, 0.5737961575261505, 0.6550883821959621, 0.5910973786341887, 0.5646336635270952, 0.5573855427454474, 0.5355064498603127, 0.4966503178942743, 0.43173287845814956, 0.42593159966713195, 0.39346829167130914, 0.39194160768559416, 0.4092920783080209, 0.3790745490271264, 0.4045805966871633, 0.36972488726770314, 0.344960451264029, 0.34174846660090186, 0.3657081220544877, 0.34188710777389186, 0.36713740329865274, 0.3452475424587399, 0.33758019246477317, 0.2870714909143716, 0.28833961891540927, 0.28934499339189235, 0.26650651710333223, 0.2856053969117116, 0.2780483323565884, 0.29948840339735144, 0.2478038393183892, 0.267106503096369, 0.23656095265726138, 0.2629874462189862, 0.2506381249463638, 0.2567763649386094, 0.2889656166527153, 0.2686734323590634, 0.2542257065025041, 0.25151753795398246, 0.28234538146133853, 0.24335357848845024, 0.24166167141101472, 0.24234422939346595, 0.22206097598378902, 0.2129773928136459, 0.2374774943306102, 0.22633048254565427, 0.245683613860054, 0.20828726328853664, 0.22227448878583253, 0.20132137038517567, 0.20748010607553116, 0.22741712855382182, 0.23579330967248602, 0.22230098900203846, 0.19924551753074377, 0.212504601655268, 0.20135597917626022, 0.20991739209269314, 0.19605803885895529, 0.1784392122546613, 0.2266674394211526, 0.18283215612653367, 0.20048614145058882, 0.1782128442301623, 0.17035642030366455, 0.20001987326051282, 0.200758069599977, 0.1798645963788821, 0.19382335300207992, 0.194387727068878, 0.19792752080395948, 0.18679154545386295, 0.19732972240407248, 0.19415174474825317, 0.19006667255220333, 0.2039185076322645, 0.19999034486368444, 0.22539402714793114, 0.17779980428370792, 0.1777349978112594, 0.18391022921373656, 0.1867579869031338, 0.19375667086785922, 0.18645021599751813, 0.1957285578326865, 0.17320835102845594]
Validation Loss:
[0.6806603670373466, 1.0336812068557593, 1.5979908106819574, 0.7887103871420255, 0.8556483515055792, 1.0436222075284385, 0.656718892595123, 0.6788969588218492, 0.7330537828085224, 0.7294390745379042, 0.8402094359233444, 0.8985239740473271, 0.8098606975994724, 0.7291990249022575, 0.7615199173306044, 0.7048968218531989, 0.6134595829976086, 0.808173287257931, 0.7531129655482462, 0.7425325584369418, 0.7023610932672778, 0.7675620459657054, 0.736482336769981, 0.7366986350342621, 0.6971623145954365, 0.718435585206774, 0.7183690310631003, 0.6964750974942889, 0.7008341427265949, 0.6755095997236057, 0.6598431111495427, 0.6800053237287753, 1.2715020831112789, 0.7273525982688481, 0.6712213511790615, 0.6943996205299795, 0.6951377688358676, 1.290443853901981, 0.6665952120377681, 0.5700889468985143, 0.5378583507293118, 0.4875603471067052, 0.4701989042373715, 0.47520703355062355, 0.4616774947795135, 0.4621283510148898, 0.44133871083562864, 0.41238181213984165, 0.4015700230029825, 0.42438110812491237, 0.4321558598518235, 0.41735402610914674, 0.3761652397352808, 0.36565532582688687, 0.3560701568829448, 0.3522356709864941, 0.34055884933272956, 0.3494196676322633, 0.3334094820746724, 0.3281624867086925, 0.31729003263401406, 0.30279691178727197, 0.2924944917676962, 0.29581415612262013, 0.2872535263260409, 0.27668396392560085, 0.2801634315861161, 0.26866222204545104, 0.2649135795619764, 0.2670219774604781, 0.276654357249458, 0.27173966996569615, 0.26876570149748497, 0.2547551743135958, 0.2632072228155766, 0.25706767144895154, 0.2627931836365411, 0.25899870097048516, 0.2566307269103664, 0.2463826019981549, 0.24857877975051396, 0.24264563021479668, 0.24019913301305035, 0.2406495490786161, 0.23680775242617666, 0.2315442280287124, 0.23781520108257764, 0.2422079800372271, 0.23078687368095896, 0.22988301729065666, 0.2249972361745631, 0.23695773269728, 0.2330465428991348, 0.2354221183570755, 0.22693515455459073, 0.23303755172937818, 0.23581460639759705, 0.23118488008395266, 0.22912292285367594, 0.2312384775215379, 0.21520581814910233, 0.219457054515588, 0.21351088598442475, 0.2201811904259009, 0.22524191275673683, 0.21433877041876923, 0.22236821146181113, 0.2245300171114322, 0.22669877592070586, 0.22670396599079293, 0.22171136445194223, 0.21667435582988276, 0.21098130676879925, 0.21685076402062822, 0.2194858840509971, 0.2201874430502612, 0.22329393710553397, 0.21900475626446628, 0.21945942935853538, 0.22611457360990028]
Train Accuracy:
[0.39285714285714285, 0.5571428571428572, 0.5357142857142857, 0.5142857142857142, 0.55, 0.4357142857142857, 0.6, 0.5571428571428572, 0.42857142857142855, 0.5428571428571428, 0.6, 0.5571428571428572, 0.5714285714285714, 0.5857142857142857, 0.6, 0.7142857142857143, 0.6285714285714286, 0.5642857142857143, 0.6, 0.6571428571428571, 0.6142857142857143, 0.6071428571428571, 0.5571428571428572, 0.7142857142857143, 0.6571428571428571, 0.6, 0.5571428571428572, 0.7428571428571429, 0.7285714285714285, 0.7, 0.7142857142857143, 0.7714285714285715, 0.7428571428571429, 0.7857142857142857, 0.6714285714285714, 0.7, 0.7285714285714285, 0.75, 0.7857142857142857, 0.7714285714285715, 0.8428571428571429, 0.7428571428571429, 0.8, 0.8428571428571429, 0.7928571428571428, 0.8642857142857143, 0.8142857142857143, 0.8, 0.8, 0.8428571428571429, 0.8928571428571429, 0.8142857142857143, 0.8357142857142857, 0.8571428571428571, 0.85, 0.8571428571428571, 0.8571428571428571, 0.9, 0.9142857142857143, 0.9285714285714286, 0.9, 0.8428571428571429, 0.9428571428571428, 0.9428571428571428, 0.9142857142857143, 0.9285714285714286, 0.9285714285714286, 0.9285714285714286, 0.9071428571428571, 0.9, 0.9142857142857143, 0.9285714285714286, 0.8857142857142857, 0.8928571428571429, 0.9, 0.9428571428571428, 0.9285714285714286, 0.9571428571428572, 0.9285714285714286, 0.9714285714285714, 0.8857142857142857, 0.9428571428571428, 0.9571428571428572, 0.9285714285714286, 0.9571428571428572, 0.9142857142857143, 0.8642857142857143, 0.9428571428571428, 0.9142857142857143, 0.9714285714285714, 0.9428571428571428, 0.9285714285714286, 0.9428571428571428, 0.9571428571428572, 0.9857142857142858, 0.9857142857142858, 0.9571428571428572, 0.9428571428571428, 0.9857142857142858, 0.9571428571428572, 0.9142857142857143, 0.9428571428571428, 0.9571428571428572, 0.9285714285714286, 0.9428571428571428, 0.9714285714285714, 0.9857142857142858, 0.9571428571428572, 0.9571428571428572, 0.9714285714285714, 0.9857142857142858, 0.9142857142857143, 0.9714285714285714, 0.9571428571428572, 0.9857142857142858, 0.9714285714285714, 0.9571428571428572, 0.9857142857142858, 0.9714285714285714, 0.9571428571428572]
Validation Accuracy:
[0.5333333333333333, 0.5333333333333333, 0.4666666666666667, 0.5333333333333333, 0.4666666666666667, 0.36666666666666664, 0.7333333333333333, 0.7, 0.6, 0.6333333333333333, 0.4666666666666667, 0.4666666666666667, 0.5, 0.5333333333333333, 0.6, 0.6, 0.6333333333333333, 0.4666666666666667, 0.5666666666666667, 0.5, 0.5333333333333333, 0.5, 0.5333333333333333, 0.6, 0.6, 0.5666666666666667, 0.5333333333333333, 0.6333333333333333, 0.6, 0.6, 0.5666666666666667, 0.5666666666666667, 0.6, 0.6, 0.6, 0.6, 0.6, 0.6333333333333333, 0.6333333333333333, 0.7166666666666667, 0.7666666666666667, 0.8, 0.8, 0.7333333333333333, 0.8, 0.8, 0.8, 0.8333333333333334, 0.8, 0.8, 0.8, 0.8166666666666667, 0.8333333333333334, 0.8333333333333334, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.8666666666666667, 0.9, 0.9, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9333333333333333, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667, 0.9666666666666667]
