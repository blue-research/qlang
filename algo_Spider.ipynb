{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5KPvszq_5dp5",
    "outputId": "16640c53-6bcc-4d43-aa7d-471b22e72e83"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from lambeq import BobcatParser\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kzh6eLX5dp8"
   },
   "source": [
    "## 1) Read in the data and create diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Still working on getting this cell to work. Bobcatarser cannot parse some sentences\n",
    "# def read_sst2(data_type=\"train\"):\n",
    "#     dataset = load_dataset(\"gpt3mix/sst2\")\n",
    "\n",
    "#     data = dataset[data_type]\n",
    "\n",
    "#     usr_data = []\n",
    "#     usr_labels = []\n",
    "\n",
    "#     for example in data:\n",
    "#         usr_data.append(example[\"text\"])\n",
    "#         usr_labels.append(example[\"label\"])\n",
    "\n",
    "#     print(\"First sentence:\", usr_data[0])\n",
    "#     print(\"First label:\", usr_labels[0])\n",
    "\n",
    "#     return usr_data,usr_labels\n",
    "\n",
    "# train_data,train_labels = read_sst2(\"train\")\n",
    "# dev_data,dev_labels = read_sst2(\"validation\")\n",
    "# test_data,test_labels = read_sst2(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            t = int(line[0])\n",
    "            labels.append([t, 1-t])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return labels, sentences\n",
    "\n",
    "\n",
    "train_labels, train_data = read_data('datasets/mc_train_data.txt')\n",
    "dev_labels, dev_data = read_data('datasets/mc_dev_data.txt')\n",
    "test_labels, test_data = read_data('datasets/mc_test_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sgu1vdBX5dqC",
    "outputId": "75e77789-eac0-4dda-8a1f-c347cb3da7e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to update model with exception: ModelDownloader raised error: Failed to download model bert. Received response status code: 202\n",
      "Attempting to continue with version 1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n",
      "Tagging sentences.\n",
      "Parsing tagged sentences.\n",
      "Turning parse trees to diagrams.\n",
      "Tagging sentences.\n"
     ]
    }
   ],
   "source": [
    "parser = BobcatParser(verbose='text')\n",
    "\n",
    "raw_train_diagrams = parser.sentences2diagrams(train_data)\n",
    "raw_dev_diagrams = parser.sentences2diagrams(dev_data)\n",
    "raw_test_diagrams = parser.sentences2diagrams(test_data)\n",
    "\n",
    "raw_train_diagrams[0].draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1AzYfKp5dqF",
    "outputId": "2f16f75b-d2e9-4027-c188-62834209d389"
   },
   "outputs": [],
   "source": [
    "\"\"\"from lambeq import RemoveCupsRewriter\n",
    "\n",
    "remove_cups = RemoveCupsRewriter()\n",
    "\n",
    "print(\"Before removing cups\")\n",
    "raw_train_diagrams[0].draw()\n",
    "\n",
    "train_diagrams = [remove_cups(diagram) for diagram in raw_train_diagrams]\n",
    "dev_diagrams = [remove_cups(diagram) for diagram in raw_dev_diagrams]\n",
    "test_diagrams = [remove_cups(diagram) for diagram in raw_test_diagrams]\n",
    "\n",
    "print(\"After removing cups\")\n",
    "train_diagrams[0].draw()\n",
    "\"\"\"\n",
    "## NOT REMOVING CUPS\n",
    "\n",
    "train_diagrams = raw_train_diagrams\n",
    "dev_diagrams = raw_dev_diagrams\n",
    "test_diagrams = raw_test_diagrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2tix1Y105dqI"
   },
   "outputs": [],
   "source": [
    "from lambeq import AtomicType, IQPAnsatz, BaseAnsatz, CircuitAnsatz, MPSAnsatz, Sim14Ansatz, Sim15Ansatz, SpiderAnsatz, StronglyEntanglingAnsatz, Symbol, TensorAnsatz\n",
    "\n",
    "#ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},\n",
    " #                  n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "from lambeq.backend.tensor import Dim\n",
    "\n",
    "N = AtomicType.NOUN\n",
    "S = AtomicType.SENTENCE\n",
    "\n",
    "# Create an ansatz \n",
    "ansatz = SpiderAnsatz({N: Dim(2), S: Dim(2)})\n",
    "\n",
    "train_circuits = [ansatz(diagram) for diagram in train_diagrams]\n",
    "dev_circuits =  [ansatz(diagram) for diagram in dev_diagrams]\n",
    "test_circuits = [ansatz(diagram) for diagram in test_diagrams]\n",
    "\n",
    "train_circuits[0].draw(figsize=(9, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQu2fk8k5dqK"
   },
   "source": [
    "# Step 5: Choosing a backend\n",
    "We are now going to choose a backend on which our quantum circuits is going to be run. In this workshop we are going to use a classical simulator (a classical computer which simulates the bahaviour of a real quantum computer) to run our circuits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NbAv3-O75dqL"
   },
   "outputs": [],
   "source": [
    "from pytket.extensions.qiskit import AerBackend\n",
    "from lambeq import TketModel\n",
    "\n",
    "all_circuits = train_circuits+dev_circuits\n",
    "\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 8192\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXneWmYr5dqN"
   },
   "source": [
    "# Step 6: Creating the quantum sentence classifier. \n",
    "\n",
    "The code below trains our quantum sentence classifier. Since the training can take a few minutes we could alternatively work with a pre-trained model which you can load from the `checkpoint.pickle` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4DGOBBP5dqO"
   },
   "outputs": [],
   "source": [
    "from lambeq import BinaryCrossEntropyLoss\n",
    "\n",
    "#model = TketModel.from_diagrams(all_circuits, backend_config=backend_config)\n",
    "\n",
    "import torch\n",
    "from lambeq import PytorchModel\n",
    "\n",
    "model = PytorchModel.from_diagrams(all_circuits)\n",
    "\n",
    "# loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "\n",
    "sig = torch.sigmoid\n",
    "\n",
    "def acc(y_hat, y):\n",
    "    return torch.sum(torch.eq(torch.round(sig(y_hat)), y))/len(y)/2  # half due to double-counting\n",
    "\n",
    "eval_metrics = {\"acc\": acc}\n",
    "\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "\n",
    "EPOCHS = 120\n",
    "BATCH_SIZE = 30\n",
    "\n",
    "from lambeq import PytorchTrainer\n",
    "\n",
    "\n",
    "trainer = PytorchTrainer(\n",
    "        model=model,\n",
    "        loss_function=torch.nn.BCEWithLogitsLoss(),\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        learning_rate=3e-2,\n",
    "        epochs=EPOCHS,\n",
    "        evaluate_functions=eval_metrics,\n",
    "        evaluate_on_train=True,\n",
    "        verbose='text',\n",
    "        seed=0)\n",
    "\n",
    "\n",
    "\n",
    "from lambeq import Dataset\n",
    "\n",
    "train_dataset = Dataset(\n",
    "            train_circuits,\n",
    "            train_labels,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset = Dataset(dev_circuits, dev_labels, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(train_dataset, val_dataset, log_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGdV9TRm5dqP"
   },
   "outputs": [],
   "source": [
    "# model = TketModel.from_checkpoint('models/classifier-IQP.pickle', backend_config=backend_config)\n",
    "model.save(\"models/classifier-Spider.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_model_performance():\n",
    "    # np_test_circuits = [c.lambdify(*vocab)(*tensors) for c in test_circuits]\n",
    "    # test_predictions =  sigmoid(np.array([c.eval(dtype=float) for c in np_test_circuits]))\n",
    "    \n",
    "    # hits = 0\n",
    "    # for i in range(len(np_test_circuits)):\n",
    "    #     target = test_targets[i]\n",
    "    #     pred = test_predictions[i]\n",
    "    #     if np.argmax(target) == np.argmax(pred):\n",
    "    #         hits += 1\n",
    "    \n",
    "    # print(\"Accuracy on test set:\", hits / len(np_test_circuits))\n",
    "    # np_test_circuits = [c.lambdify(*vocab)(*tensors) for c in test_circuits]\n",
    "    # test_dataset = Dataset(test_circuits, test_labels, shuffle=False)\n",
    "    test_pred = model.get_diagram_output(test_circuits)\n",
    "    # print(f\"test acc: {test_acc:.4f}\")\n",
    "    total = 0\n",
    "    for i in range(len(test_pred)):\n",
    "        if test_pred[i][0]>=0.5:\n",
    "            test_pred[i][0],test_pred[i][1]=1.0,0.0\n",
    "        else:\n",
    "            test_pred[i][0],test_pred[i][1]=0.0,1.0\n",
    "        if test_pred[i][0]==test_labels[i][0] and test_pred[i][1]==test_labels[i][1]:\n",
    "            total+=1\n",
    "    return total/len(test_labels)\n",
    "measure_model_performance()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "workshop.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
